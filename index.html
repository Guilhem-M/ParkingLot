<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Parking lot Supervision by Video Surveillance by Guilhem-M</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Parking lot Supervision by Video Surveillance</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/Guilhem-M/ParkingLot" class="btn">View on GitHub</a>
      <a href="https://github.com/Guilhem-M/ParkingLot/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/Guilhem-M/ParkingLot/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="1-goal" class="anchor" href="#1-goal" aria-hidden="true"><span class="octicon octicon-link"></span></a>Goal</h1>

<p>The goal of this project is to design and develop a system which can supervise a parking lot by video surveillance.  Basically, with an input video the system should be able to detect for each parking space if a car is parked or not.</p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11765253/8bc557e0-a10c-11e5-95c2-e37cf3987ee1.png" align="middle"/>

<h1>
<a id="2-why-it-is-important" class="anchor" href="#2-why-it-is-important" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why it is important</h1>

<p>Several times a day we have to park our car in a parking lot: to go to work, shopping, restaurant… In urban areas, the number of cars can exceed the number of parking space. That can lead to a waste of time for the driver and troubles for the other car in the road in the case of a double park. On the other hand, people are always trying to find the best parking space (the one which is the closest to the final destination), that is why people are circling around and waste gas and time.
An underground parking lot is easy to supervise; the only thing to do is to count the vehicle entrance and exit using barrier gates and tickets. But in the case of a free open-air parking lot with different entrances and exits, the video surveillance system is a cheap easy to install solution. 
We can imagine a parking lot supervised by several cameras, with an algorithm detecting the availability of the parking spaces, running on a server. Then the drivers can know the best/nearest parking space available when they enter in the parking lot, thanks to an application installed on their smartphone. </p>

<h1>
<a id="0-Abstract" class="anchor" href="#0-Abstract" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract</h1>
<p>During this project I have implemented an algorithm to detect the availability of a parking space based on a simple video of a parking lot. The videos were taken from the 2nd floor of Greaves Hall (USU), looking to its parking lot, with a gopro.
A background substractor and a simple tracker has been implemented. At this point the system is able to detect the state of the parking lot when only one car is moving in the parking lot, however I proposed a method to extend the detection in the case of several cars moving at the same time.
The accuracy of the system is hard to determine, indeed I had access to the camera only few hours, that is why I could not evaluate with precision the robustness of the system. </p>

<h1>
<a id="3-approach" class="anchor" href="#3-approach" aria-hidden="true"><span class="octicon octicon-link"></span></a>Approach</h1>

<h2>
<a id="31-general-idea" class="anchor" href="#31-general-idea" aria-hidden="true"><span class="octicon octicon-link"></span></a>General idea</h2>

<p>The general idea is to separate the background and the foreground of the video. The foreground is a map of the part that has changed between the current frame and the previous frames. The foreground represents all the movements in the image.
If we detect movements on parking space, the state (vacant or not) of the space may have changed.</p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11615135/e3cbeb3a-9c15-11e5-8490-2d8ae293ba56.png" align="middle"/>


<h2>
<a id="32-volume-estimation-and-probabilistic-representation-of-a-parking-space" class="anchor" href="#32-volume-estimation-and-probabilistic-representation-of-a-parking-space" aria-hidden="true"><span class="octicon octicon-link"></span></a>Volume estimation and probabilistic representation of a parking space</h2>

<p>The current system need as an input the 2D coordinates of each parking space relative to the image. But a better representation of a parking space is a volume. Indeed a car parked on a space occupied a certain volume, and because we cannot have a camera looking perfectly perpendicular to the parking lot, we have to deal with perspective effects and possible inter-occlusion between cars. 
I decided to implement the idea found in [1]:
The first step is to estimate the 3D volume of a car parked on a parking space. Knowing the 2D coordinates of the parking space, a good approximation of the height of car parked on the parking space is to take half of the average of the four sides. Then we can construct a 2D parallelepiped which represents the volume of the parking space.
</p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11232767/ca6e075a-8d73-11e5-901c-6c4a6d3ebaa3.png" align="middle"/>

<p>The next step is to give a different weight for each pixel inside the parallelepiped. Indeed we know that if a car is parked on a parking spot, the car is most likely lying around the center of the space. That is why, a 2D Gaussian function, centered on the center of the volume, is used to set the weight of each pixel inside the volume. 
The next step is to give a lower weight to the pixel belonging to several parking spaces. Indeed, due to the perspective, two parking spaces volume can overlap each other. </p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11769362/a6bfd9d0-a1a2-11e5-9bf3-fd61a0fbeba0.png" align="middle"/>

<h2>
<a id="33-background-subtraction" class="anchor" href="#33-background-subtraction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Background subtraction</h2>

<p>This step takes care of detecting the objects which are moving in the video: we consider as the foreground the objects which are moving, and as the foreground everything that stays stationary.
A naïve approach could be to simply to take the absolute difference between the current frame and the previous frame. However due to the noise of the camera, the evolution of the lighting condition, the small displacement (wind blowing leaves), the result is not accurate.
The technique of mixture of Gaussians [2] solves these problems by establishing a model of the background. Each pixel’s intensity is modeled as a mixture of three to five Gaussian functions. The parameters and weight of each Gaussian is updated from frame to frame by an expectation maximization algorithm and the foreground is determined by thresholding. </p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11232768/cbdc0c40-8d73-11e5-944e-f2d4217b6bca.png" align="middle"/>

<h2>
<a id="34-tracking" class="anchor" href="#34-tracking" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tracking</h2>

<p>Now that the moving objects are extracted, we can track them and see if their trajectories start or end in a parking spot.
To track the objects which are moving in the parking lot we need to process the foreground and to cluster it. A blob detector can be used to perform this task. Depending of the size and the shape of each blob the image, the algorithm returns only the relevant blobs. </p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11765108/5f25baa4-a107-11e5-86f0-5c9e3f7d920c.png" align="middle"/>

<p> Then we need to track those blobs to get their trajectories. Because the trajectory can be noisy, and disappeared due to occlusion, a Kalman filter can be used to filter and predict the trajectory.</p>

<img src="https://cloud.githubusercontent.com/assets/15863335/11765134/d100cf1a-a107-11e5-826d-61b65b6606a8.png" align="middle"/>

<h2>
<a id="35-space-state-updating" class="anchor" href="#34-space-state-updating" aria-hidden="true"><span class="octicon octicon-link"></span></a>Space state update</h2>

<p>Then we can process each trajectory and if it is long enough, look at the beginning and try to find if it lies on one or several parking volume. In the case of several possible parking spaces (due to 3D volume overlapping), the one which returns the highest probability is chosen.  Then we can assume that a car (or other object) has left the space and we can update the state to vacant. 
We apply the same to the end of the trajectory, but in the case that it ends in a parking spot we update the state to occupied.</p>

<h1>
<a id="4-results-and-demo" class="anchor" href="#4-results-and-demo" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results and Demo</h1>

<p>I only had access to the camera for few hours, I was not able to test my algorithm on many different cases.
However for the parking spaces on the closest line to the camera, my algorithm has an accuracy of 100% based on 10 different cases.
For the others spaces I have only few cases, and the accuracy seems to be lower due to occlusion and distance. 
An easy way to increase the accuracy, is to add several camera at different places.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/lMr0rjS0v9A" frameborder="0" allowfullscreen></iframe>

<h1>
<a id="5-future-work" class="anchor" href="#5-future-work" aria-hidden="true"><span class="octicon octicon-link"></span></a>Future work</h1>

<p>Currently the system works only if one car is moving at a time in the parking lot. The next step is to handle multiple car tracking (blob detection in the foreground and Kalman filter to track every moving object).
A fixed camera running all the day will allow to record the accuracy of the system with a human action to label each parking space in each frame. </p>

<h1>
<a id="6-references" class="anchor" href="#6-references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h1>

<p>[1] DELIBALTOV, Diana, WU, Wencheng, LOCE, Robert P., et al. Parking lot occupancy determination from lamp-post camera images. In : Intelligent Transportation Systems-(ITSC), 2013 16th International IEEE Conference on. IEEE, 2013. p. 2387-2392.</p>

<p>[2] KAEWTRAKULPONG, Pakorn et BOWDEN, Richard. An improved adaptive background mixture model for real-time tracking with shadow detection. In : Video-based surveillance systems. Springer US, 2002. p. 135-144.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/Guilhem-M/ParkingLot">Parking lot Supervision by Video Surveillance</a> is maintained by <a href="https://github.com/Guilhem-M">Guilhem-M</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
